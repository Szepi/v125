---
title: Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks
abstract: " We study the problem of PAC learning one-hidden-layer ReLU networks with
  $k$ hidden units on $\\mathbb{R}^d$ under Gaussian marginals in the presence of
  additive label noise. For the case of positive coefficients, we give the first polynomial-time
  algorithm for this learning problem for $k$ up to $\\tilde{O}(\\sqrt{\\log d})$.
  Previously, no polynomial time algorithm was known, even for $k=3$. This answers
  an open question posed by Klivans (2017). Importantly, our algorithm does not require
  any assumptions about the rank of the weight matrix and its complexity is independent
  of its condition number. On the negative side, for the more general task of PAC
  learning one-hidden-layer ReLU networks with arbitrary real coefficients, we prove
  a Statistical Query lower bound of $d^{\\Omega(k)}$. Thus, we provide a separation
  between the two classes in terms of efficient learnability. Our upper and lower
  bounds are general, extending to broader families of activation functions. "
layout: inproceedings
series: Proceedings of Machine Learning Research
id: diakonikolas20d
month: 0
tex_title: Algorithms and SQ Lower Bounds for PAC Learning One-Hidden-Layer ReLU Networks
firstpage: 1514
lastpage: 1539
page: 1514-1539
order: 1514
cycles: false
bibtex_author: Diakonikolas, Ilias and Kane, Daniel M. and Kontonis, Vasilis and Zarifis,
  Nikos
author:
- given: Ilias
  family: Diakonikolas
- given: Daniel M.
  family: Kane
- given: Vasilis
  family: Kontonis
- given: Nikos
  family: Zarifis
date: 2020-07-15
address: 
publisher: PMLR
container-title: Proceedings of Thirty Third Conference on Learning Theory
volume: '125'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 15
pdf: http://proceedings.mlr.press/v125/diakonikolas20d/diakonikolas20d.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
