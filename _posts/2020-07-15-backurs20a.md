---
title: Active Local Learning
abstract: " In this work we consider active {\\em local learning}: given a query point
  $x$, and active access to an unlabeled training set $S$, output the prediction $h(x)$
  of a near-optimal $h \\in H$ using significantly fewer labels than would be needed
  to actually learn $h$ fully. In particular, the number of label queries should be
  independent of the complexity of $H$, and the function $h$ should be well-defined,
  independent of $x$.  This immediately also implies an algorithm for {\\em distance
  estimation}: estimating the value $opt(H)$ from many fewer labels than needed to
  actually learn a near-optimal $h \\in H$, by running local learning on a few random
  query points and computing the average error. For the hypothesis class consisting
  of functions supported on the interval $[0,1]$ with Lipschitz constant bounded by
  $L$, we present an algorithm that makes $O(({1 / \\epsilon^6}) \\log(1/\\epsilon))$
  label queries from an unlabeled pool of $O(({L / \\epsilon^4})\\log(1/\\epsilon))$
  samples. It estimates the distance to the best hypothesis in the class to an additive
  error of $\\epsilon$ for an arbitrary underlying distribution. We further generalize
  our algorithm to more than one dimensions. We emphasize that the number of labels
  used is independent of the complexity of the hypothesis class which is linear in
  $L$ in the one-dimensional case. Furthermore, we give an algorithm to locally estimate
  the values of a near-optimal function at a few query points of interest with number
  of labels independent of $L$. We also consider the related problem of approximating
  the minimum error that can be achieved by the Nadaraya-Watson estimator under a
  linear diagonal transformation with eigenvalues coming from a small range. For a
  $d$-dimensional pointset of size $N$, our algorithm achieves an additive approximation
  of $\\epsilon$, makes $\\tilde{O}({d}/{\\epsilon^2})$ queries and runs in $\\tilde{O}({d^2}/{\\epsilon^{d+4}}+{dN}/{\\epsilon^2})$
  time. "
layout: inproceedings
series: Proceedings of Machine Learning Research
id: backurs20a
month: 0
tex_title: Active Local Learning
firstpage: 363
lastpage: 390
page: 363-390
order: 363
cycles: false
bibtex_author: Backurs, Arturs and Blum, Avrim and Gupta, Neha
author:
- given: Arturs
  family: Backurs
- given: Avrim
  family: Blum
- given: Neha
  family: Gupta
date: 2020-07-15
address: 
publisher: PMLR
container-title: Proceedings of Thirty Third Conference on Learning Theory
volume: '125'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 15
pdf: http://proceedings.mlr.press/v125/backurs20a/backurs20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
