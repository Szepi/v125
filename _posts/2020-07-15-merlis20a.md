---
title: Tight Lower Bounds for Combinatorial Multi-Armed Bandits
abstract: " The Combinatorial Multi-Armed Bandit problem is a sequential decision-making
  problem in which an agent selects a set of arms on each round, observes feedback
  for each of these arms and aims to maximize a known reward function of the arms
  it chose. While previous work proved regret upper bounds in this setting for general
  reward functions, only a few works provided matching lower bounds, all for specific
  reward functions. In this work, we prove regret lower bounds for combinatorial bandits
  that hold under mild assumptions for all smooth reward functions. We derive both
  problem-dependent and problem-independent bounds and show that the recently proposed
  Gini-weighted smoothness parameter (Merlis and Mannor, 2019) also determines the
  lower bounds for monotone reward functions. Notably, this implies that our lower
  bounds are tight up to log-factors."
layout: inproceedings
series: Proceedings of Machine Learning Research
id: merlis20a
month: 0
tex_title: Tight Lower Bounds for Combinatorial Multi-Armed Bandits
firstpage: 2830
lastpage: 2857
page: 2830-2857
order: 2830
cycles: false
bibtex_author: Merlis, Nadav and Mannor, Shie
author:
- given: Nadav
  family: Merlis
- given: Shie
  family: Mannor
date: 2020-07-15
address: 
publisher: PMLR
container-title: Proceedings of Thirty Third Conference on Learning Theory
volume: '125'
genre: inproceedings
issued:
  date-parts:
  - 2020
  - 7
  - 15
pdf: http://proceedings.mlr.press/v125/merlis20a/merlis20a.pdf
extras: []
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
